---
title: "07_Likelihood"
author: "Hannah Stroud"
date: "October 22, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readr)
library(ggplot2)
library(modelr)
library(dplyr)
library(MASS)
library(profileModel)
library(tidyr)
```

## 1. Grid Sampling! Load up the pufferfish data and use grid sampling to find the MLE of the slope, intercept and residual SD of this model. Feel free to eyeball results from an lm() fit to get reasonable values. Try not to do this for a grid of more than ~100K points (more if you want!). It’s ok to be coarse. Compare to lm.
```{r}
puff <-read_csv("./Data/16q11PufferfishMimicry Caley & Schluter 2003.csv")

#coarse scale lm
summary(lm(puff$predators~puff$resemblance))

#build function
lhood_func  <- function(slope, inter, r_sd) {
  #data gen process (mx +b where x=resemblance)
  pred_fit <- inter + slope* puff$resemblance
  
  #likelihood
  sum(dnorm(puff$predators, pred_fit , r_sd, log=TRUE ))
}

#grid sample 
puff_grid <- crossing(slope= seq(2.5, 3.5, 0.05), 
                      inter= seq(0.5, 4, 0.05),
                      r_sd=seq(2.9, 3.1, 0.01)) %>% 
  rowwise() %>% 
  mutate(logl= lhood_func(slope, inter, r_sd))%>%
  ungroup()
puff_grid%>% filter(logl== max(logl))
```

## 2. Surfaces! Filter the dataset to the MLE of the SD. Plot the surface for the slope and intercept in whatever way you find most compelling. You might want to play around with zooming in to different regions, etc. Have fun!
```{r}

```

## 3. GLM! Now, compare those results to results from glm. Show the profiles and confidence intervals from glm() for the slope and intercept.

##4. Get Outside of GLM! So, often, we have more complex models than the above. There are a variety of optimizers out there, and packages for accessing them. One of the best is bbmle by Ecologist Ben Bolker (whose dad is emeritus at UMB in computer science! Go visit him! He’s fantastic!)

##Load up 'bbmle and try out mle2. It’s a bit different, in that the first argument is a function that minimizes the log likelihood (not maximizes). The second argument is a list of start values - e.g. list(slope = 2, intercept = 5, resid_sd = 2). Try and fit your model with mle2 using start values close to the actual estimates. Look at the summary and plot the profile. Note, you might get a lot of errors because it will try impossible values of your residual SD. Also, note thatyou’ll have to rewrite your likelihood function to return the negative log likelihood (or write a wrapper that does so). A small thing

5. Start values! What happens if you start with start values very far away from the initial values. Failing here is fine. But what do you think is happening, and what does this say about the value of start values?

6. Algorithms! By default, mle2 uses the Nelder-Mead algorithm via the optim function. What happens if you add an method argument to “SANN” or “L-BFGS-B” (and for the later, which is bounded sampling, give it a lower argument for your residual value, so it’s always positive). See  ?optim for some more guidance. Do these both converge to the same value? Based on their profiles, do you trust them? (Note, Simulated annealing takes a looooong time. Go have a cuppa while the profile for that one runs).
